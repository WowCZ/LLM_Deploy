srun: job 1151136 queued and waiting for resources
srun: job 1151136 has been allocated resources
srun: Job 1151136 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is normal

Traceback (most recent call last):
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/connectionpool.py", line 996, in _prepare_proxy
    conn.connect()
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/connection.py", line 374, in connect
    self._tunnel()
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/http/client.py", line 905, in _tunnel
    raise OSError("Tunnel connection failed: %d %s" % (code,
OSError: Tunnel connection failed: 503 Service Unavailable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/requests/adapters.py", line 489, in send
    resp = conn.urlopen(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/completions (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/openai/api_requestor.py", line 516, in request_raw
    result = _thread_context.session.request(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/requests/sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/requests/sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/requests/adapters.py", line 559, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/completions (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable')))

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "api_server.py", line 12, in <module>
    model_api = DavinciAPI()
  File "/mnt/petrelfs/chenzhi/workspace/LLM/llm_api/davinci.py", line 17, in __init__
    super(DavinciAPI, self).__init__(model_name, model_path)
  File "/mnt/petrelfs/chenzhi/workspace/LLM/llm_api/base_api.py", line 11, in __init__
    self.model, self.tokenizer = self._initialize_llm()
  File "/mnt/petrelfs/chenzhi/workspace/LLM/llm_api/davinci.py", line 26, in _initialize_llm
    completion = openai.Completion.create(model="text-davinci-003",
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/openai/api_resources/completion.py", line 25, in create
    return super().create(*args, **kwargs)
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py", line 153, in create
    response, _, api_key = requestor.request(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/openai/api_requestor.py", line 216, in request
    result = self.request_raw(
  File "/mnt/petrelfs/chenzhi/miniconda3/envs/llm/lib/python3.8/site-packages/openai/api_requestor.py", line 529, in request_raw
    raise error.APIConnectionError(
openai.error.APIConnectionError: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/completions (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable')))
srun: error: SH-IDC1-10-140-24-70: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=1151136.0
